{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chart_studio\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/ import string\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>just ran thr contract negotiation ough the rain</td>\n",
       "      <td>contract negotiation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Another loser: ****. I have lost the game more...</td>\n",
       "      <td>supply chain management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Went to get dog from vets, theyve stitched her...</td>\n",
       "      <td>cost reduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I made my parents add u guys on the family st...</td>\n",
       "      <td>strategic sourcing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Link di materials dn`t work</td>\n",
       "      <td>materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344443</th>\n",
       "      <td>16344433</td>\n",
       "      <td>I`ve listed lots of enterprise software  new b...</td>\n",
       "      <td>enterprise software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344444</th>\n",
       "      <td>16344434</td>\n",
       "      <td>I`m not value based selling  a hobo.</td>\n",
       "      <td>value based selling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344445</th>\n",
       "      <td>16344435</td>\n",
       "      <td>That would have been fun BUT we were soooo TI...</td>\n",
       "      <td>sales presentations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344446</th>\n",
       "      <td>16344436</td>\n",
       "      <td>here btw, thi selling s is not a bot</td>\n",
       "      <td>selling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344447</th>\n",
       "      <td>16344437</td>\n",
       "      <td>That`s exactly why I prefer to give money and ...</td>\n",
       "      <td>enterprise software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16344448 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  \\\n",
       "0                1    just ran thr contract negotiation ough the rain   \n",
       "1                2  Another loser: ****. I have lost the game more...   \n",
       "2                3  Went to get dog from vets, theyve stitched her...   \n",
       "3                4   I made my parents add u guys on the family st...   \n",
       "4                5                        Link di materials dn`t work   \n",
       "...            ...                                                ...   \n",
       "16344443  16344433  I`ve listed lots of enterprise software  new b...   \n",
       "16344444  16344434               I`m not value based selling  a hobo.   \n",
       "16344445  16344435   That would have been fun BUT we were soooo TI...   \n",
       "16344446  16344436               here btw, thi selling s is not a bot   \n",
       "16344447  16344437  That`s exactly why I prefer to give money and ...   \n",
       "\n",
       "                    selected_text  \n",
       "0            contract negotiation  \n",
       "1         supply chain management  \n",
       "2                  cost reduction  \n",
       "3              strategic sourcing  \n",
       "4                       materials  \n",
       "...                           ...  \n",
       "16344443      enterprise software  \n",
       "16344444      value based selling  \n",
       "16344445      sales presentations  \n",
       "16344446                  selling  \n",
       "16344447      enterprise software  \n",
       "\n",
       "[16344448 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = 'ModelData/'\n",
    "\n",
    "train_df = pd.read_csv('SkillSets_eng_all.csv', encoding= 'unicode_escape')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>just ran thr contract negotiation ough the rain</td>\n",
       "      <td>contract negotiation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Another loser: ****. I have lost the game more...</td>\n",
       "      <td>supply chain management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Went to get dog from vets, theyve stitched her...</td>\n",
       "      <td>cost reduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I made my parents add u guys on the family st...</td>\n",
       "      <td>strategic sourcing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Link di materials dn`t work</td>\n",
       "      <td>materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344443</th>\n",
       "      <td>16344433</td>\n",
       "      <td>I`ve listed lots of enterprise software  new b...</td>\n",
       "      <td>enterprise software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344444</th>\n",
       "      <td>16344434</td>\n",
       "      <td>I`m not value based selling  a hobo.</td>\n",
       "      <td>value based selling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344445</th>\n",
       "      <td>16344435</td>\n",
       "      <td>That would have been fun BUT we were soooo TI...</td>\n",
       "      <td>sales presentations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344446</th>\n",
       "      <td>16344436</td>\n",
       "      <td>here btw, thi selling s is not a bot</td>\n",
       "      <td>selling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344447</th>\n",
       "      <td>16344437</td>\n",
       "      <td>That`s exactly why I prefer to give money and ...</td>\n",
       "      <td>enterprise software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16344429 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  \\\n",
       "0                1    just ran thr contract negotiation ough the rain   \n",
       "1                2  Another loser: ****. I have lost the game more...   \n",
       "2                3  Went to get dog from vets, theyve stitched her...   \n",
       "3                4   I made my parents add u guys on the family st...   \n",
       "4                5                        Link di materials dn`t work   \n",
       "...            ...                                                ...   \n",
       "16344443  16344433  I`ve listed lots of enterprise software  new b...   \n",
       "16344444  16344434               I`m not value based selling  a hobo.   \n",
       "16344445  16344435   That would have been fun BUT we were soooo TI...   \n",
       "16344446  16344436               here btw, thi selling s is not a bot   \n",
       "16344447  16344437  That`s exactly why I prefer to give money and ...   \n",
       "\n",
       "                    selected_text  \n",
       "0            contract negotiation  \n",
       "1         supply chain management  \n",
       "2                  cost reduction  \n",
       "3              strategic sourcing  \n",
       "4                       materials  \n",
       "...                           ...  \n",
       "16344443      enterprise software  \n",
       "16344444      value based selling  \n",
       "16344445      sales presentations  \n",
       "16344446                  selling  \n",
       "16344447      enterprise software  \n",
       "\n",
       "[16344429 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.dropna()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelData//SkillModel\n"
     ]
    }
   ],
   "source": [
    "print(f'{BASE_PATH}/SkillModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_dir, nlp, new_model_name):\n",
    "    output_dir = f'{BASE_PATH}/SkillModel'\n",
    "    if output_dir is not None:        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        nlp.meta[\"name\"] = new_model_name\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass model = nlp if you want to train on top of existing model \n",
    "\n",
    "def train(train_data, output_dir, n_iter=20, model=None):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    \"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(output_dir)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # add labels\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "#         if model is None:\n",
    "#             nlp.begin_training()\n",
    "#         else:\n",
    "#             nlp.resume_training()\n",
    "        optimizer = nlp.begin_training()\n",
    "\n",
    "        for itn in tqdm(range(n_iter)):\n",
    "            random.shuffle(train_data)\n",
    "#             batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n",
    "            losses = {}\n",
    "            for text, annotations in train_data:\n",
    "                nlp.update(\n",
    "                   [text],  # batch of texts\n",
    "                   [annotations],  # batch of annotations\n",
    "                   drop=0.2,  # dropout - make it harder to memorise data\n",
    "                   sgd=optimizer,  # callable to update weights\n",
    "                   losses=losses)\n",
    "\n",
    "#             print(losses)\n",
    "            \n",
    "            print(\"Losses\", losses)\n",
    "    save_model(output_dir, nlp, 'st_ner')\n",
    "    print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating data in spacy data input format\n",
    "\n",
    "def get_training_data():\n",
    "    train_data = []\n",
    "    for index, row in train_df[:5000].iterrows():        \n",
    "        selected_text = row.selected_text\n",
    "        text = row.text\n",
    "        start = text.find(selected_text)\n",
    "        end = start + len(selected_text)\n",
    "        train_data.append((text, {\"entities\": [(start, end, 'SKILL')]}))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_out_path():\n",
    "    model_out_path = None\n",
    "    model_out_path = '/models/model_skill'\n",
    "    \n",
    "    return model_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('just ran thr contract negotiation ough the rain',\n",
       "  {'entities': [(13, 33, 'SKILL')]})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = get_training_data()\n",
    "train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/models/model_skill'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = get_model_out_path()\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n",
      "Inside Lines {line}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "training_data = []\n",
    "lines=[]\n",
    "\n",
    "with open(\"SkillSet.json\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    #print (lines)\n",
    "    \n",
    "for line in lines:\n",
    "    print(\"Inside Lines {line}\")\n",
    "    data = json.loads(line)\n",
    "    text = data['content']\n",
    "    entities = []\n",
    "    for annotation in data['annotation']:\n",
    "        #only a single point in text annotation.\n",
    "        point = annotation['points'][0]\n",
    "        labels = annotation['label']\n",
    "        # handle both list of labels or a single label.\n",
    "        if not isinstance(labels, list):\n",
    "            labels = [labels]\n",
    "            \n",
    "        for label in labels:\n",
    "           #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
    "           entities.append((point['start'], point['end'] + 1 ,label))\n",
    "           \n",
    "        training_data.append((text, {\"entities\" : entities}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete this content which is mixing with main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "# training_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def train_SkillSet_NER(training_data,model=None, output_dir=model_path, n_iter=20):\n",
    "                       \n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")                  \n",
    "     \n",
    "    #print(nlp.pipe_names)\n",
    "\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "            ner = nlp.create_pipe('ner')\n",
    "            nlp.add_pipe(ner, last=True)\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in training_data:\n",
    "         for ent in annotations.get('entities'):\n",
    "             ner.add_label(ent[2])\n",
    "\n",
    "     # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "\n",
    "        for itn in tqdm(range(n_iter)):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(training_data)\n",
    "            losses = {}\n",
    "\n",
    "            for text, annotations in training_data:\n",
    "               nlp.update(\n",
    "                   [text],  # batch of texts\n",
    "                   [annotations],  # batch of annotations\n",
    "                   drop=0.2,  # dropout - make it harder to memorise data\n",
    "                   sgd=optimizer,  # callable to update weights\n",
    "                   losses=losses)\n",
    "\n",
    "            print(\"Losses\", losses)                      \n",
    "                       \n",
    "                       \n",
    "     # save model to output directory\n",
    "    save_model(output_dir, nlp, 'st_ner')\n",
    "    print(output_dir)\n",
    "\n",
    "        # test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Statring iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [05:31<05:31, 331.32s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 5723.207422131477}\n",
      "Statring iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [11:44<00:00, 352.49s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3399.180533825123}\n",
      "Saved model to ModelData//SkillModel\n",
      "ModelData//SkillModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_SkillSet_NER(train_data,output_dir='ModelData//SkillModel', model=None,n_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Deletion for Data turk code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:11<03:30, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 244.53184608040425}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [00:21<03:17, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 172.42652361771303}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [00:32<03:05, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 105.95389736275818}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [00:43<02:55, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 121.50807639267734}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [00:54<02:44, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 99.18175953762366}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [01:05<02:33, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 100.61867019910687}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [01:16<02:21, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 104.51516429617935}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [01:27<02:11, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 79.58382547957788}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [01:39<02:05, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 101.11615488004135}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [01:53<01:59, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 107.55387823041524}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [02:06<01:52, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 101.32614096741104}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [02:20<01:42, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 26.103505990101926}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [02:33<01:31, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 91.493064793508}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [02:47<01:18, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 43.6797292367124}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [03:00<01:06, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 6.2800314586064845}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [03:13<00:52, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 16.59102139581775}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [03:27<00:39, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 11.963221889247974}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [03:33<00:22, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 9.121594558452427}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [03:37<00:08,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 1.407101637038274}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [03:42<00:00, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3.990713726843727}\n",
      "Saved model to ModelData//SkillModel\n",
      "/models/model_skill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for demo purpose i am just training the model for 2 iterations, feel free to experiment.\n",
    "train(train_data[:1000], model_path, n_iter=20, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(text, model):\n",
    "    doc = model(text)\n",
    "    ent_array = []\n",
    "    for ent in doc.ents:\n",
    "        start = text.find(ent.text)\n",
    "        end = start + len(ent.text)\n",
    "        new_int = [start, end, ent.label_]\n",
    "        if new_int not in ent_array:\n",
    "            ent_array.append([start, end, ent.label_])\n",
    "    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n",
    "    return selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "model_skill = spacy.load(\"ModelData\\SkillModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web services'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_entities(\"Java, WCF, ASP.Net, C#, web services and many more\".lower(), model_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities= ['photography -> SKILL', 'facial animation -> SKILL', 'microsoft office\\nmicrosoft excel -> SKILL', 'leadership -> SKILL', 'xml -> SKILL']\n"
     ]
    }
   ],
   "source": [
    "desc = \"\"\"\n",
    "My computer is SO slooowww this morning.  I think it fine art photography `s a sign that I should go home and play in my yard.\n",
    "\n",
    "Main Responsibility / Job Summary :\n",
    "\n",
    "facial animation\n",
    "autodesk motionbuilder\n",
    "xsi\n",
    "3d graphics\n",
    "c++\n",
    "low level programming\n",
    "abap\n",
    "microsoft office\n",
    "microsoft excel\n",
    "microsoft word\n",
    "powerpoint\n",
    "teaching\n",
    "html\n",
    "c++\n",
    "c\n",
    "ability to work under strict deadlines and pressure times\n",
    "ability of multi-tasking\n",
    "ability to lead multi-disciplined teams\n",
    "strong leadership, project management and team building skills\n",
    "strong problem solving and analytical skills\n",
    "managing teams and work under critical deadlines and in challenging environments\n",
    "strong business acumen\n",
    "excellent communication skills\n",
    "strong at business and peer relationship management\n",
    "\n",
    "\n",
    "\n",
    "- Web based application development experience using Asp.Net, C#, JavaScript, Jquery, CSS, XML, AJAX and JSON.\n",
    "\n",
    "\"\"\"\n",
    "doc2 = model_skill(desc.lower())\n",
    "print (\"Entities= \" + str([\"\" + str(ent.text) + \" -> \" + str(ent.label_) for ent in doc2.ents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities= []\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"ModelData\\SkillModel\"\n",
    "\n",
    "nlp2 = spacy.load(model_dir)\n",
    "desc = \"\"\"\n",
    "Java Developer with J23EE AND Tomcat\"\"\"\n",
    "doc2 = nlp2(desc.lower())\n",
    "\n",
    "print (\"Entities= \" + str([\"\" + str(ent.text) + \" -> \" + str(ent.label_) for ent in doc2.ents]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
